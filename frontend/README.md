# Frontend Service

Video calling interface with real-time AI filters.

## Features

- ğŸ¥ HD video streaming (1280x720)
- ğŸ¤– Real-time AI face detection (TensorFlow.js BlazeFace)
- ğŸ¨ Multiple filters: Blur, Grayscale, Sepia, Face Detection
- ğŸ“± Responsive design (Tailwind CSS)
- ğŸ”„ Automatic reconnection
- ğŸ” Auto-renegotiation (onnegotiationneeded) + ICE restart
- ğŸ“‰ Adaptive bitrate/resolution based on connection quality
- ğŸ‘¥ Multi-peer video calling

## Tech Stack

- **Framework**: Next.js 14 (App Router)
- **UI**: React 18, Tailwind CSS
- **AI/ML**: TensorFlow.js, BlazeFace model
- **WebRTC**: Native RTCPeerConnection API
- **Real-time**: Socket.IO Client
- **Language**: TypeScript

## Getting Started

```bash
npm install
npm run dev
```

Open http://localhost:3000

## Environment Variables

Create `.env.local`:

```bash
NEXT_PUBLIC_API_URL=http://localhost:4000
NEXT_PUBLIC_WS_URL=http://localhost:5000
NEXT_PUBLIC_STUN_URL=stun:localhost:3478
NEXT_PUBLIC_TURN_URL=turn:localhost:3478
NEXT_PUBLIC_TURN_USERNAME=cnwebuser
NEXT_PUBLIC_TURN_PASSWORD=cnwebpass

# Notes
- TURN credentials are optional but recommended for NAT traversal.
- If unset, the app falls back to public STUN servers.
```

## Video Processing Pipeline

1. **Capture**: `getUserMedia()` â†’ Camera stream
2. **Process**: Draw to canvas â†’ Apply AI/filters
3. **Stream**: `captureStream()` â†’ Processed video
4. **Send**: Add to RTCPeerConnection â†’ Transmit to peers

## Project Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx              # Home (create/join room)
â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â”œâ”€â”€ globals.css           # Global styles
â”‚   â””â”€â”€ room/[roomId]/
â”‚       â””â”€â”€ page.tsx          # Video call room
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ VideoGrid.tsx         # Video layout
â”‚   â”œâ”€â”€ VideoControls.tsx     # Mute/video controls
â”‚   â””â”€â”€ FilterSelector.tsx    # Filter buttons
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ socket.ts             # Socket.IO client
â”‚   â”œâ”€â”€ webrtc.ts             # WebRTC logic
â”‚   â””â”€â”€ filters.ts            # AI/Filter processing
â””â”€â”€ types/
    â””â”€â”€ index.ts              # TypeScript types
```

## Available Filters

- **None**: Original video
- **Blur**: Gaussian blur effect
- **Grayscale**: Black & white
- **Sepia**: Vintage tone
- **Face Detection**: Real-time face tracking with landmarks

## Development

### Hot Reload
Changes to files trigger automatic reload.

### Debug Tips
- Open Chrome DevTools (F12)
- Check Console for errors
- Use chrome://webrtc-internals/ for WebRTC debugging
- Observe renegotiation and ICE restarts in console logs
- Monitor Network tab for API calls

## Build

```bash
npm run build
npm start
```

## Docker

```bash
docker build -t cnweb-frontend .
docker run -p 3000:3000 cnweb-frontend
```

## Browser Support

- Chrome 90+
- Firefox 88+
- Edge 90+
- Safari 15+ (limited)

Requires WebRTC support and camera/microphone permissions.
